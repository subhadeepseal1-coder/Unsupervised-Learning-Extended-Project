{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrBB4haxqcLI"
      },
      "source": [
        "# Unsupervised Learning: OnSports"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement"
      ],
      "metadata": {
        "id": "yXSESiiNlb-f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZBlyMyBfsZM"
      },
      "source": [
        "### Context\n",
        "\n",
        "Fantasy sports are online gaming platforms where participants draft and manage virtual teams of real professional sports players. Based on the performance of the players in the real world, players are allotted points in the fantasy sports platform every match. The objective is to create the best possible team with a fixed budget to score maximum fantasy points, and users compete against each other over an entire sports league or season. Some of these fantasy sports require actual financial investments for participation, with the chances of winning monetary rewards as well as free matchday tickets on a periodic basis.\n",
        "\n",
        "The fantasy sports market has seen tremendous growth over the past few years, with a valuation of \\\\$18.6 billion in 2019. The football (soccer) segment led in terms of market share in 2019, with over 8 million participants worldwide, and is expected to retain its dominance over the next couple of years. Digitalization is one of the primary factors driving the growth of the fantasy sports market as it allows participants the opportunity to compete on a global level and test their skills. With an increase in smartphone usage and availability of fantasy sports apps, this market is expected to witness a globe surge and reach a \\\\$48.6 billion valuation by 2027.\n",
        "\n",
        "\n",
        "### Objective\n",
        "\n",
        "OnSports is a fantasy sports platform which has fantasy leagues for many different sports and has witnessed an increasing number of participants globally over the past 5 years. For each player, a price is set at the start, and the price keeps changing over time based on the performance of the players in the real world. With the new English Premier League season about to start, they have collected data of the past season and want to analyze it to determine the price of each player for the start of the new season. OnSports have hired you as a data scientist and asked you to conduct a cluster analysis to identify players of different potentials of each player based on previous season performance. This will help them understand the patterns in player performances and fantasy returns and decide the exact price to be set for each player for the upcoming football season.\n",
        "\n",
        "### Data Dictionary\n",
        "\n",
        "- Player_Name: Name of the player\n",
        "- Club: Club in which the player plays\n",
        "- Position: Position in which the player plays\n",
        "- Goals_Scored: Number of goals scored by the player in the previous season\n",
        "- Assists: Number of passes made by the player leading to goals in the previous season\n",
        "- Total_Points: Total number of fantasy points scored by the player in the previous season\n",
        "- Minutes: Number of minutes played by the player in the previous season\n",
        "- Goals_Conceded: Number of goals conceded by the player in the previous season\n",
        "- Creativity: A score, computed using a range of stats, that assesses player performance in terms of producing goalscoring opportunities for other players\n",
        "- Influence: A score, computed using a range of stats, that evaluates a player's impact on a match, taking into account actions that could directly or indirectly affect the match outcome\n",
        "- Threat: A score, computed using a range of stats, that gauges players who are most likely to score goals\n",
        "- Bonus: Total bonus points received (The three best performing players in each match receive additional bonus points based on a score computed using a range of stats. 3 points are awarded to the highest scoring player, 2 to the second best, and 1 to the third.)\n",
        "- Clean_Sheets: Number of matches without conceding a goal in the previous season"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LltJMKBfsZT"
      },
      "source": [
        "## Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the libraries with the specified version.\n",
        "# uncomment and run the following line if Google Colab is being used\n",
        "#!pip install scikit-learn==1.2.2 seaborn==0.13.1 matplotlib==3.7.1 numpy==1.25.2 pandas==1.5.3 yellowbrick==1.5 -q --user"
      ],
      "metadata": {
        "id": "cr91NfLfJ3kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the libraries with the specified version.\n",
        "# uncomment and run the following lines if Jupyter Notebook is being used\n",
        "# !pip install scikit-learn==1.2.2 seaborn==0.13.1 matplotlib==3.7.1 numpy==1.25.2 pandas==1.5.2 yellowbrick==1.5 -q --user\n",
        "# !pip install --upgrade -q jinja2"
      ],
      "metadata": {
        "id": "k7py409a9C2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: *After running the above cell, kindly restart the notebook kernel and run all cells sequentially from the start again.*"
      ],
      "metadata": {
        "id": "zRXW-f7c9Ffg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XntzoLq5qcLR"
      },
      "outputs": [],
      "source": [
        "# Libraries to help with reading and manipulating data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Libraries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_theme(style='darkgrid')\n",
        "\n",
        "# Removes the limit for the number of displayed columns\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "# Sets the limit for the number of displayed rows\n",
        "pd.set_option(\"display.max_rows\", 200)\n",
        "\n",
        "# to scale the data using z-score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# to compute distances\n",
        "from scipy.spatial.distance import cdist, pdist\n",
        "\n",
        "# to perform k-means clustering and compute silhouette scores\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# to visualize the elbow curve and silhouette scores\n",
        "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
        "\n",
        "# to perform hierarchical clustering, compute cophenetic correlation, and create dendrograms\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet\n",
        "\n",
        "# to suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the dataset"
      ],
      "metadata": {
        "id": "Hm7KgGlU3IIZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrHsmGqMqcLT"
      },
      "outputs": [],
      "source": [
        "## Complete the code to import the data\n",
        "data = pd.read_csv('____')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview of the Dataset"
      ],
      "metadata": {
        "id": "EmcUelfD3gP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The initial steps to get an overview of any dataset is to:\n",
        "- observe the first few rows of the dataset, to check whether the dataset has been loaded properly or not\n",
        "- get information about the number of rows and columns in the dataset\n",
        "- find out the data types of the columns to ensure that data is stored in the preferred format and the value of each property is as expected.\n",
        "- check the statistical summary of the dataset to get an overview of the numerical columns of the data"
      ],
      "metadata": {
        "id": "_fhnpafoI1GX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the shape of the dataset"
      ],
      "metadata": {
        "id": "hwQCJyE03W61"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "oW6CxAobqcLT"
      },
      "outputs": [],
      "source": [
        "# checking shape of the data\n",
        "print(f\"There are {'______'} rows and {'______'} columns.\") ## Complete the code to get the shape of data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Displaying few rows of the dataset"
      ],
      "metadata": {
        "id": "v85RmCY83qfc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "aCRG7aTIqcLT"
      },
      "outputs": [],
      "source": [
        "# let's view a sample of the data\n",
        "data.sample(n=10, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the data types of the columns for the dataset"
      ],
      "metadata": {
        "id": "D6y0mZgY3zA8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28jfSnk3qcLU"
      },
      "outputs": [],
      "source": [
        "# checking the column names and datatypes\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a copy of original data"
      ],
      "metadata": {
        "id": "Bzr4r3ua3usT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DC_dM4SKqcLU"
      },
      "outputs": [],
      "source": [
        "# copying the data to another variable to avoid any changes to original data\n",
        "df = data.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking for duplicates and missing values"
      ],
      "metadata": {
        "id": "7qcQovqA31ZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WapzauPrhmV7"
      },
      "outputs": [],
      "source": [
        "# checking for duplicate values\n",
        "df.'_______' ## Complete the code to get total number of duplicate values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SceBeha-qcLU"
      },
      "outputs": [],
      "source": [
        "# checking for missing values in the data\n",
        "df.'_______' ## Complete the code to check the missing values in the data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistical summary of the dataset"
      ],
      "metadata": {
        "id": "sSju8Xrl4HZk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW4-5-GUhmV8"
      },
      "source": [
        "**Let's check the statistical summary of the data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK1yhbXgqcLU"
      },
      "outputs": [],
      "source": [
        "df.describe(include='all').T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhPuzWO7hmV8"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOLKLDyZqcLV"
      },
      "source": [
        "### Univariate analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tYp_KnLqcLV"
      },
      "outputs": [],
      "source": [
        "# function to plot a boxplot and a histogram along the same scale.\n",
        "\n",
        "\n",
        "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (12,7))\n",
        "    kde: whether to the show density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
        "        nrows=2,  # Number of rows of the subplot grid= 2\n",
        "        sharex=True,  # x-axis will be shared among all subplots\n",
        "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
        "        figsize=figsize,\n",
        "    )  # creating the 2 subplots\n",
        "    sns.boxplot(\n",
        "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
        "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
        "    sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
        "    ) if bins else sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
        "    )  # For histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
        "    )  # Add mean to the histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
        "    )  # Add median to the histogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7peDmHWxqcLV"
      },
      "source": [
        "**`Goals_Scored`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWCtOx9yqcLV"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(df, 'Goals_Scored')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m5FaUQFqcLW"
      },
      "source": [
        "**`Assists`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJn245X5qcLW"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('_______')  ## Complete the code to create histogram_boxplot for 'Assists'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J5lBAwtqcLW"
      },
      "source": [
        "**`Goals_Conceded`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWlxNduAqcLW"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('_______')  ## Complete the code to create histogram_boxplot for 'Goals_Conceded'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrg_M44RqcLW"
      },
      "source": [
        "**`Clean_Sheets`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXLeQIvmqcLW"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('_______')  ## Complete the code to create histogram_boxplot for 'Clean_Sheets'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3v4D8SVqcLW"
      },
      "source": [
        "**`Minutes`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSkt_Kb2qcLW"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('_______')  ## Complete the code to create histogram_boxplot for 'Minutes'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOiSOEFtqcLX"
      },
      "source": [
        "**`Total_Points`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAY_PHWLqcLX"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('_______')  ## Complete the code to create histogram_boxplot for 'Total_Points'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqvmzHayqcLX"
      },
      "source": [
        "**`Creativity`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IO2LsePbqcLX"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('_______')  ## Complete the code to create histogram_boxplot for 'Creativity'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHsxNI2IqcLX"
      },
      "source": [
        "**`Influence`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPdA1nrdqcLX"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('_______')  ## Complete the code to create histogram_boxplot for 'Influence'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCNWnq0tqcLX"
      },
      "source": [
        "**`Threat`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdungAmlqcLX"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('_______')  ## Complete the code to create histogram_boxplot for 'Threat'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_nkwOuNqcLX"
      },
      "source": [
        "**`Bonus`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJwxoUpfqcLX"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('_______')  ## Complete the code to create histogram_boxplot for 'Bonus'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUwt-WELqcLY"
      },
      "outputs": [],
      "source": [
        "# function to create labeled barplots\n",
        "\n",
        "\n",
        "def labeled_barplot(data, feature, perc=False, n=None):\n",
        "    \"\"\"\n",
        "    Barplot with percentage at the top\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    perc: whether to display percentages instead of count (default is False)\n",
        "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
        "    \"\"\"\n",
        "\n",
        "    total = len(data[feature])  # length of the column\n",
        "    count = data[feature].nunique()\n",
        "    if n is None:\n",
        "        plt.figure(figsize=(count + 1, 5))\n",
        "    else:\n",
        "        plt.figure(figsize=(n + 1, 5))\n",
        "\n",
        "    plt.xticks(rotation=90, fontsize=15)\n",
        "    ax = sns.countplot(\n",
        "        data=data,\n",
        "        x=feature,\n",
        "        palette=\"Paired\",\n",
        "        order=data[feature].value_counts().index[:n].sort_values(),\n",
        "    )\n",
        "\n",
        "    for p in ax.patches:\n",
        "        if perc == True:\n",
        "            label = \"{:.1f}%\".format(\n",
        "                100 * p.get_height() / total\n",
        "            )  # percentage of each class of the category\n",
        "        else:\n",
        "            label = p.get_height()  # count of each level of the category\n",
        "\n",
        "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
        "        y = p.get_height()  # height of the plot\n",
        "\n",
        "        ax.annotate(\n",
        "            label,\n",
        "            (x, y),\n",
        "            ha=\"center\",\n",
        "            va=\"center\",\n",
        "            size=12,\n",
        "            xytext=(0, 5),\n",
        "            textcoords=\"offset points\",\n",
        "        )  # annotate the percentage\n",
        "\n",
        "    plt.show()  # show the plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM4eeuUrqcLY"
      },
      "source": [
        "**`Club`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB-LkM49qcLY"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(df, 'Club')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU1rS0zRqcLY"
      },
      "source": [
        "**`Position`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkoF9kUOqcLY"
      },
      "outputs": [],
      "source": [
        "labeled_barplot('_______')  ## Complete the code to create a labelled barplot for 'Position'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga_huJrnhmWE"
      },
      "source": [
        "### Bivariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpJxawjAhmWE"
      },
      "outputs": [],
      "source": [
        "# correlation check\n",
        "cols_list = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "plt.figure(figsize=(15, 7))\n",
        "sns.heatmap(\n",
        "    df[cols_list].corr(numeric_only = True), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\"\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_eEouV1qcLY"
      },
      "source": [
        "**Let's check players from which team have scored the most fantasy points on average.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaqWFTLRqcLZ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.barplot(data=df, x='___', y='___', ci=False)  ## Complete the code to choose the right variables\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yX2o9yJqcLZ"
      },
      "source": [
        "**We know that players in different positions have specific roles to play in a team. Let's check players in which positions tend to score more fantasy points on average.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t76VlO_NqcLZ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.barplot(data=df, x='___', y='___', ci=False)  ## Complete the code to choose the right variables\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j85IhJ79qcLZ"
      },
      "source": [
        "**To effectively utilize their squad depth, managers often rotate the squad to keep key players in shape for tougher games. Let's check the total number of minutes played, on average, across different positions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGC0cWU2qcLe"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.barplot(data=df, x='___', y='___', ci=False)  ## Complete the code to choose the right variables\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkOdHX5RqcLf"
      },
      "source": [
        "**Every point counts in fantasy sports and getting bonus points for a player is always a treat. Let's check which team's players have secured the most bonus points, on average, last season.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2QU_ohyqcLf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.barplot(data=df, x='___', y='___', ci=False)  ## Complete the code to choose the right variables\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2cKJXs6qcLg"
      },
      "source": [
        "**Let's see which players scored the most fantasy points last season for different positions of play.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uLwAgmWqcLg"
      },
      "outputs": [],
      "source": [
        "pos_list = df.Position.unique().tolist()\n",
        "best_df = pd.DataFrame()\n",
        "\n",
        "for pos in pos_list:\n",
        "    df_aux = df[df.Position == pos]\n",
        "    best_df = pd.concat([best_df, df_aux[df_aux.Total_Points == df_aux.Total_Points.max()][['Player_Name', 'Club', 'Position', 'Total_Points']]])\n",
        "\n",
        "best_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "YFldVnH-I9Sl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDZgev7iqcLg"
      },
      "source": [
        "### Outlier Check\n",
        "\n",
        "- Let's plot the boxplots of all numerical columns to check for outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IebwiAZqcLh"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "numeric_columns = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "for i, variable in enumerate(numeric_columns):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.boxplot(df[variable], whis=1.5)\n",
        "    plt.tight_layout()\n",
        "    plt.title(variable)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Siuoo6NOqcLh"
      },
      "source": [
        "### Scaling\n",
        "\n",
        "- Let's scale the data before we proceed with clustering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJjuig-hqcLh"
      },
      "outputs": [],
      "source": [
        "# scaling the data before clustering\n",
        "scaler = StandardScaler()\n",
        "subset = \"___\"  ## Complete the code to get the scaled data\n",
        "subset_scaled = scaler.fit_transform(subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1AJgq_VqcLi"
      },
      "outputs": [],
      "source": [
        "# creating a dataframe of the scaled data\n",
        "subset_scaled_df = pd.DataFrame(subset_scaled, columns=subset.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7m9mJRZqcLi"
      },
      "source": [
        "## K-means Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking Elbow Plot"
      ],
      "metadata": {
        "id": "8qinndqpJFcQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01YnG9-YqcLi"
      },
      "outputs": [],
      "source": [
        "k_means_df = subset_scaled_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl0hOZpCqcLi"
      },
      "outputs": [],
      "source": [
        "clusters = range(1, 15)\n",
        "meanDistortions = []\n",
        "\n",
        "for k in clusters:\n",
        "    model = KMeans(n_clusters=k, random_state=1)\n",
        "    model.fit(subset_scaled_df)\n",
        "    prediction = model.predict(k_means_df)\n",
        "    distortion = (\n",
        "        sum(np.min(cdist(k_means_df, model.cluster_centers_, \"euclidean\"), axis=1))\n",
        "        / k_means_df.shape[0]\n",
        "    )\n",
        "\n",
        "    meanDistortions.append(distortion)\n",
        "\n",
        "    print(\"Number of Clusters:\", k, \"\\tAverage Distortion:\", distortion)\n",
        "\n",
        "plt.plot(clusters, meanDistortions, \"bx-\")\n",
        "plt.xlabel(\"k\")\n",
        "plt.ylabel(\"Average Distortion\")\n",
        "plt.title(\"Selecting k with the Elbow Method\", fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHTWGbNFqcLj"
      },
      "outputs": [],
      "source": [
        "model = KMeans(random_state=1)\n",
        "visualizer = KElbowVisualizer(model, k=(1, 15), timings=True)\n",
        "visualizer.fit(k_means_df)  # fit the data to the visualizer\n",
        "visualizer.show()  # finalize and render figure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VIgju4dxrIC"
      },
      "source": [
        "### Let's check the silhouette scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MszEz6hqcLj"
      },
      "outputs": [],
      "source": [
        "sil_score = []\n",
        "cluster_list = range(2, 15)\n",
        "for n_clusters in cluster_list:\n",
        "    clusterer = KMeans(n_clusters=n_clusters, random_state=1)\n",
        "    preds = clusterer.fit_predict((subset_scaled_df))\n",
        "    score = silhouette_score(k_means_df, preds)\n",
        "    sil_score.append(score)\n",
        "    print(\"For n_clusters = {}, the silhouette score is {})\".format(n_clusters, score))\n",
        "\n",
        "plt.plot(cluster_list, sil_score)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw4_UfBRqcLk"
      },
      "outputs": [],
      "source": [
        "model = KMeans(random_state=1)\n",
        "visualizer = KElbowVisualizer(model, k=(2, 15), metric=\"silhouette\", timings=True)\n",
        "visualizer.fit(k_means_df)  # fit the data to the visualizer\n",
        "visualizer.show()  # finalize and render figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5K20pemqcLk"
      },
      "outputs": [],
      "source": [
        "# finding optimal no. of clusters with silhouette coefficients\n",
        "visualizer = SilhouetteVisualizer(KMeans('___', random_state=1))  ## Complete the code to visualize the silhouette scores for certain number of clusters\n",
        "visualizer.fit(k_means_df)\n",
        "visualizer.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Final Model"
      ],
      "metadata": {
        "id": "NZ1Ec654JPGd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cPUQr48qcLk"
      },
      "outputs": [],
      "source": [
        "# final K-means model\n",
        "kmeans = KMeans(n_clusters='___', random_state=1)  ## Complete the code to choose the number of clusters\n",
        "kmeans.fit(k_means_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xmhtr5ovqcLl"
      },
      "outputs": [],
      "source": [
        "# creating a copy of the original data\n",
        "df1 = df.copy()\n",
        "\n",
        "# adding kmeans cluster labels to the original and scaled dataframes\n",
        "k_means_df[\"KM_segments\"] = kmeans.labels_\n",
        "df1[\"KM_segments\"] = kmeans.labels_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbfMHPDKfsa_"
      },
      "source": [
        "### Cluster Profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXj8WP79qcLl"
      },
      "outputs": [],
      "source": [
        "km_cluster_profile = df1.groupby(\"___\").mean(numeric_only = True)  ## Complete the code to groupby the cluster labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhgS8BAzqcLm"
      },
      "outputs": [],
      "source": [
        "km_cluster_profile[\"count_in_each_segment\"] = (\n",
        "    df1.groupby(\"___\")[\"Total_Points\"].count().values  ## Complete the code to groupby the cluster labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bA9ReVeqcLm"
      },
      "outputs": [],
      "source": [
        "km_cluster_profile.style.highlight_max(color=\"lightgreen\", axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "_zHGltj2qcLm"
      },
      "outputs": [],
      "source": [
        "## Complete the code to print the players in each cluster\n",
        "for cl in df1[\"___\"].unique():\n",
        "    print(\"In cluster {}, the following players are present:\".format(cl))\n",
        "    print(df1[df1[\"___\"] == cl][\"Player_Name\"].unique())\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHXNwaiKqcLm"
      },
      "outputs": [],
      "source": [
        "df1.groupby([\"KM_segments\", \"Position\"])['Player_Name'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8uTjZL5qcLn"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "plt.suptitle(\"Boxplot of numerical variables for each cluster\")\n",
        "\n",
        "# selecting numerical columns\n",
        "num_col = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "for i, variable in enumerate(num_col):\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    sns.boxplot(data=df1, x=\"KM_segments\", y=variable)\n",
        "\n",
        "plt.tight_layout(pad=2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iKq6JiCqcLn"
      },
      "source": [
        "## Hierarchical Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing Cophenetic Correlation"
      ],
      "metadata": {
        "id": "lyZNLbb24zO3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgQ39GcDqcLn"
      },
      "outputs": [],
      "source": [
        "hc_df = subset_scaled_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_1raWRdqcLo"
      },
      "outputs": [],
      "source": [
        "# list of distance metrics\n",
        "distance_metrics = [\"euclidean\", \"chebyshev\", \"mahalanobis\", \"cityblock\"]\n",
        "\n",
        "# list of linkage methods\n",
        "linkage_methods = [\"single\", \"complete\", \"average\", \"weighted\"]\n",
        "\n",
        "high_cophenet_corr = 0\n",
        "high_dm_lm = [0, 0]\n",
        "\n",
        "for dm in distance_metrics:\n",
        "    for lm in linkage_methods:\n",
        "        Z = linkage(hc_df, metric=dm, method=lm)\n",
        "        c, coph_dists = cophenet(Z, pdist(hc_df))\n",
        "        print(\n",
        "            \"Cophenetic correlation for {} distance and {} linkage is {}.\".format(\n",
        "                dm.capitalize(), lm, c\n",
        "            )\n",
        "        )\n",
        "        if high_cophenet_corr < c:\n",
        "            high_cophenet_corr = c\n",
        "            high_dm_lm[0] = dm\n",
        "            high_dm_lm[1] = lm\n",
        "\n",
        "# printing the combination of distance metric and linkage method with the highest cophenetic correlation\n",
        "print('*'*100)\n",
        "print(\n",
        "    \"Highest cophenetic correlation is {}, which is obtained with {} distance and {} linkage.\".format(\n",
        "        high_cophenet_corr, high_dm_lm[0].capitalize(), high_dm_lm[1]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WkmUejSqcLo"
      },
      "source": [
        "**Let's explore different linkage methods with Euclidean distance only.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tREtHg2DqcLo"
      },
      "outputs": [],
      "source": [
        "# list of linkage methods\n",
        "linkage_methods = [\"single\", \"complete\", \"average\", \"centroid\", \"ward\", \"weighted\"]\n",
        "\n",
        "high_cophenet_corr = 0\n",
        "high_dm_lm = [0, 0]\n",
        "\n",
        "for lm in linkage_methods:\n",
        "    Z = linkage(hc_df, metric=\"euclidean\", method=lm)\n",
        "    c, coph_dists = cophenet(Z, pdist(hc_df))\n",
        "    print(\"Cophenetic correlation for {} linkage is {}.\".format(lm, c))\n",
        "    if high_cophenet_corr < c:\n",
        "        high_cophenet_corr = c\n",
        "        high_dm_lm[0] = \"euclidean\"\n",
        "        high_dm_lm[1] = lm\n",
        "\n",
        "# printing the combination of distance metric and linkage method with the highest cophenetic correlation\n",
        "print('*'*100)\n",
        "print(\n",
        "    \"Highest cophenetic correlation is {}, which is obtained with {} linkage.\".format(\n",
        "        high_cophenet_corr, high_dm_lm[1]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKaOoNqcqcLp"
      },
      "source": [
        "**Let's view the dendrograms for the different linkage methods with Euclidean distance only.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking Dendrograms"
      ],
      "metadata": {
        "id": "WfGygoZp47c-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v027dgMPqcLp"
      },
      "outputs": [],
      "source": [
        "# list of linkage methods\n",
        "linkage_methods = [\"single\", \"complete\", \"average\", \"centroid\", \"ward\", \"weighted\"]\n",
        "\n",
        "# lists to save results of cophenetic correlation calculation\n",
        "compare_cols = [\"Linkage\", \"Cophenetic Coefficient\"]\n",
        "compare = []\n",
        "\n",
        "# to create a subplot image\n",
        "fig, axs = plt.subplots(len(linkage_methods), 1, figsize=(15, 30))\n",
        "\n",
        "# We will enumerate through the list of linkage methods above\n",
        "# For each linkage method, we will plot the dendrogram and calculate the cophenetic correlation\n",
        "for i, method in enumerate(linkage_methods):\n",
        "    Z = linkage(hc_df, metric=\"euclidean\", method=method)\n",
        "\n",
        "    dendrogram(Z, ax=axs[i])\n",
        "    axs[i].set_title(f\"Dendrogram ({method.capitalize()} Linkage)\")\n",
        "\n",
        "    coph_corr, coph_dist = cophenet(Z, pdist(hc_df))\n",
        "    axs[i].annotate(\n",
        "        f\"Cophenetic\\nCorrelation\\n{coph_corr:0.2f}\",\n",
        "        (0.80, 0.80),\n",
        "        xycoords=\"axes fraction\",\n",
        "    )\n",
        "\n",
        "    compare.append([method, coph_corr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUSKzjqeqcLq"
      },
      "outputs": [],
      "source": [
        "# create and print a dataframe to compare cophenetic correlations for different linkage methods\n",
        "df_cc = pd.DataFrame(compare, columns=compare_cols)\n",
        "df_cc = df_cc.sort_values(by=\"Cophenetic Coefficient\")\n",
        "df_cc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating model using sklearn"
      ],
      "metadata": {
        "id": "5UB39umrJO04"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9Z41OfYqcLq"
      },
      "outputs": [],
      "source": [
        "HCmodel = AgglomerativeClustering(n_clusters='___', affinity='___', linkage='___')  ## Complete the code to define the hierarhical clustering model\n",
        "HCmodel.fit(hc_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ND4qFJJEqcLq"
      },
      "outputs": [],
      "source": [
        "# creating a copy of the original data\n",
        "df2 = df.copy()\n",
        "\n",
        "# adding hierarchical cluster labels to the original and scaled dataframes\n",
        "hc_df[\"HC_segments\"] = HCmodel.labels_\n",
        "df2[\"HC_segments\"] = HCmodel.labels_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H9X4DxgqcLq"
      },
      "source": [
        "### Cluster Profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dhc9DH2NqcLr"
      },
      "outputs": [],
      "source": [
        "hc_cluster_profile = df2.groupby(\"___\").mean(numeric_only = True)  ## Complete the code to groupby the cluster labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w00fh3GqcLr"
      },
      "outputs": [],
      "source": [
        "hc_cluster_profile[\"count_in_each_segment\"] = (\n",
        "    df2.groupby(\"___\")[\"Total_Points\"].count().values  ## Complete the code to groupby the cluster labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72lwBCAQqcLr"
      },
      "outputs": [],
      "source": [
        "hc_cluster_profile.style.highlight_max(color=\"lightgreen\", axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "HOtrXR7RqcLs"
      },
      "outputs": [],
      "source": [
        "## Complete the code to print the players in each cluster\n",
        "for cl in df2[\"____\"].unique():\n",
        "    print(\"In cluster {}, the following companies are present:\".format(cl))\n",
        "    print(df2[df2[\"___\"] == cl][\"Security\"].unique())\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjPZmsI7qcLs"
      },
      "outputs": [],
      "source": [
        "df2.groupby([\"HC_segments\", \"Position\"])['Player_Name'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQU-ivnPqcLs"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "plt.suptitle(\"Boxplot of numerical variables for each cluster\")\n",
        "\n",
        "for i, variable in enumerate(num_col):\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    sns.boxplot(data=df2, x=\"HC_segments\", y=variable)\n",
        "\n",
        "plt.tight_layout(pad=2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqTXv64iqcLt"
      },
      "source": [
        "## K-means vs Hierarchical Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSnjtLxfqcLt"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxrEHj3ihmWO"
      },
      "source": [
        "## Actionable Insights and Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-\n"
      ],
      "metadata": {
        "id": "NZXrXDlmnYYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "___"
      ],
      "metadata": {
        "id": "29GA5LCynZFg"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yXSESiiNlb-f",
        "7LltJMKBfsZT",
        "Hm7KgGlU3IIZ",
        "EmcUelfD3gP4",
        "hwQCJyE03W61",
        "v85RmCY83qfc",
        "D6y0mZgY3zA8",
        "Bzr4r3ua3usT",
        "7qcQovqA31ZM",
        "sSju8Xrl4HZk",
        "DhPuzWO7hmV8",
        "rOLKLDyZqcLV",
        "Ga_huJrnhmWE",
        "YFldVnH-I9Sl",
        "DDZgev7iqcLg",
        "Siuoo6NOqcLh",
        "j7m9mJRZqcLi",
        "8qinndqpJFcQ",
        "1VIgju4dxrIC",
        "NZ1Ec654JPGd",
        "CbfMHPDKfsa_",
        "6iKq6JiCqcLn",
        "lyZNLbb24zO3",
        "WfGygoZp47c-",
        "5UB39umrJO04",
        "7H9X4DxgqcLq",
        "IqTXv64iqcLt",
        "nxrEHj3ihmWO"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}